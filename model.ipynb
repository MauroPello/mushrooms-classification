{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup e test librerie\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest\n",
    "\n",
    "XGboost\n",
    "\n",
    "evaluation\n",
    "\n",
    "overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18356 entries, 0 to 18355\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   is-edible             18356 non-null  bool   \n",
      " 1   cap-diameter          18356 non-null  float64\n",
      " 2   cap-shape             18356 non-null  float64\n",
      " 3   cap-surface           18356 non-null  float64\n",
      " 4   cap-color             18356 non-null  float64\n",
      " 5   does-bruise-or-bleed  18356 non-null  bool   \n",
      " 6   gill-attachment       18356 non-null  float64\n",
      " 7   gill-spacing          18356 non-null  float64\n",
      " 8   gill-color            18356 non-null  float64\n",
      " 9   stem-height           18356 non-null  float64\n",
      " 10  stem-width            18356 non-null  float64\n",
      " 11  stem-root             18356 non-null  float64\n",
      " 12  stem-surface          18356 non-null  float64\n",
      " 13  stem-color            18356 non-null  float64\n",
      " 14  veil-color            18356 non-null  float64\n",
      " 15  has-ring              18356 non-null  float64\n",
      " 16  ring-type             18356 non-null  float64\n",
      " 17  spore-print-color     18356 non-null  float64\n",
      " 18  habitat               18356 non-null  float64\n",
      " 19  season                18356 non-null  float64\n",
      "dtypes: bool(2), float64(18)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "mushrooms = pd.read_csv(\"mushrooms_cleaned.csv\")\n",
    "\n",
    "y = mushrooms[\"is-edible\"]\n",
    "X = mushrooms.drop(columns=\"is-edible\")\n",
    "\n",
    "mushrooms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=1/3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(X, y, model):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(f\"Accuracy/Score: {accuracy:.5}\")\n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coefficients(classifier):\n",
    "    print(\"Coefficients\")\n",
    "    for i in range(len(X.columns)):\n",
    "        print(f\"{X.columns[i]}: {classifier.coef_[0][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy/Score: 0.8052\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85      3933\n",
      "        True       0.73      0.71      0.72      2186\n",
      "\n",
      "    accuracy                           0.81      6119\n",
      "   macro avg       0.79      0.78      0.79      6119\n",
      "weighted avg       0.80      0.81      0.80      6119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(solver=\"saga\"))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# print_coefficients(model.named_steps[\"lr\"])\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy/Score: 0.93218\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.95      0.95      3933\n",
      "        True       0.90      0.91      0.91      2186\n",
      "\n",
      "    accuracy                           0.93      6119\n",
      "   macro avg       0.93      0.93      0.93      6119\n",
      "weighted avg       0.93      0.93      0.93      6119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"dtc\", DecisionTreeClassifier(max_depth=5))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy/Score: 0.80618\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85      3933\n",
      "        True       0.74      0.70      0.72      2186\n",
      "\n",
      "    accuracy                           0.81      6119\n",
      "   macro avg       0.79      0.78      0.79      6119\n",
      "weighted avg       0.80      0.81      0.80      6119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rc\", RidgeClassifier(alpha=0.5))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# print_coefficients(model.named_steps[\"rc\"])\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "\n",
    "kf = KFold(3, shuffle=True, random_state=42)\n",
    "skf = StratifiedKFold(3, shuffle=True, random_state=42)\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", None),\n",
    "    (\"lr\", LogisticRegression(solver=\"saga\"))\n",
    "])\n",
    "grid = [\n",
    "    {\n",
    "        \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
    "        \"lr__penalty\": [None]\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
    "        \"lr__penalty\": [\"l2\", \"l1\"],\n",
    "        \"lr__C\": np.logspace(-2, 2, 5)\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
    "        \"lr__penalty\": [\"elasticnet\"],\n",
    "        \"lr__C\": np.logspace(-2, 2, 5),\n",
    "        \"lr__l1_ratio\": [0.2, 0.5]\n",
    "    }\n",
    "]\n",
    "# gs = GridSearchCV(model, grid, cv=skf)\n",
    "# gs.fit(X, y)\n",
    "# pd.DataFrame(gs.cv_results_).sort_values(\"rank_test_score\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size aiuta tantissimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_mlp__hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.783981</td>\n",
       "      <td>0.090735</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>(20, 20, 20)</td>\n",
       "      <td>{'mlp__hidden_layer_sizes': (20, 20, 20)}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.648498</td>\n",
       "      <td>0.313843</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>6</td>\n",
       "      <td>{'mlp__hidden_layer_sizes': 6}</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.054533</td>\n",
       "      <td>0.174493</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>(6, 4)</td>\n",
       "      <td>{'mlp__hidden_layer_sizes': (6, 4)}</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       1.783981      0.090735         0.007072        0.000700   \n",
       "0       2.648498      0.313843         0.005370        0.000133   \n",
       "1       2.054533      0.174493         0.005552        0.000271   \n",
       "\n",
       "  param_mlp__hidden_layer_sizes                                     params  \\\n",
       "2                  (20, 20, 20)  {'mlp__hidden_layer_sizes': (20, 20, 20)}   \n",
       "0                             6             {'mlp__hidden_layer_sizes': 6}   \n",
       "1                        (6, 4)        {'mlp__hidden_layer_sizes': (6, 4)}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "2           1.000000           1.000000           1.000000         1.000000   \n",
       "0           0.999755           1.000000           0.999755         0.999837   \n",
       "1           0.999755           0.999755           0.999755         0.999755   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "2        0.000000                1  \n",
       "0        0.000116                2  \n",
       "1        0.000000                3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlp\", MLPClassifier(batch_size=50, activation=\"relu\", random_state=42))\n",
    "])\n",
    "grid = {\n",
    "    \"mlp__hidden_layer_sizes\": [6, (6, 4), (20, 20, 20)],\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=skf)\n",
    "gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"rank_test_score\").head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
